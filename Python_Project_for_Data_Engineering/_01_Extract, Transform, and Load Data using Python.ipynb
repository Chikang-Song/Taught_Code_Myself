{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298f59fc",
   "metadata": {},
   "source": [
    "## **Introduction**  \n",
    "\n",
    "**ETL(Extract, Transform, Load)** ì‘ì—…ì€ **ë°ì´í„° ì—”ì§€ë‹ˆì–´** ì—­í• ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ê³¼ì •ì…ë‹ˆë‹¤.  \n",
    "\n",
    "- **Extract(ì¶”ì¶œ)**: ì—¬ëŸ¬ ì†ŒìŠ¤ì™€ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë‹¨ê³„  \n",
    "- **Transform(ë³€í™˜)**: ì¶”ì¶œëœ ë°ì´í„°ë¥¼ **ë¯¸ë¦¬ ì •ì˜ëœ ì„¤ì •**ì— ë§ê²Œ ë³€í™˜í•˜ëŠ” ë‹¨ê³„  \n",
    "- **Load(ì ì¬)**: ë³€í™˜ëœ ë°ì´í„°ë¥¼ **ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬**í•˜ì—¬ ì¶”ê°€ ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” ë‹¨ê³„  \n",
    "\n",
    "ì´ ì‹¤ìŠµì—ì„œëŠ” **ETL ì‘ì—…ì„ ì§ì ‘ ìˆ˜í–‰**í•˜ë©° ì‹¤ìŠµ ê²½í—˜ì„ ìŒ“ê²Œ ë©ë‹ˆë‹¤. ğŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c2a30",
   "metadata": {},
   "source": [
    "## **Objectives (ëª©í‘œ)**  \n",
    "\n",
    "ì´ ì‹¤ìŠµì„ ì™„ë£Œí•œ í›„, ë‹¤ìŒì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  \n",
    "\n",
    "1ï¸âƒ£ **CSV, JSON, XML íŒŒì¼ ì½ê¸°**  \n",
    "2ï¸âƒ£ ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ **í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ**  \n",
    "3ï¸âƒ£ **ë°ì´í„°ë¥¼ í•„ìš”í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜**  \n",
    "4ï¸âƒ£ ë³€í™˜ëœ ë°ì´í„°ë¥¼ **RDBMS(Relational Database Management System)**ì— **ì ì¬ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2e326",
   "metadata": {},
   "source": [
    "## **Initial Steps (ì´ˆê¸° ë‹¨ê³„)**  \n",
    "\n",
    "ETL í”„ë¡œì„¸ìŠ¤ì˜ ì²« ë‹¨ê³„ëŠ” **ê¸°ë³¸ í”„ë¡œì íŠ¸ í´ë”(IDEì˜ default project folder)**ì— **ìƒˆ íŒŒì¼ì„ ìƒì„±**í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ **íŒŒì¼ ìƒì„± ë°©ë²•:**\n",
    "\n",
    "1ï¸âƒ£ **ë©”ë‰´ ë°”**ì—ì„œ **File íƒ­**ì„ í´ë¦­í•©ë‹ˆë‹¤.  \n",
    "2ï¸âƒ£ **New File**ì„ ì„ íƒí•˜ì—¬ **ìƒˆ íŒŒì¼**ì„ ë§Œë“­ë‹ˆë‹¤.  \n",
    "3ï¸âƒ£ **íŒŒì¼ ì´ë¦„**ì„ **`etl_code.py`**ë¡œ ì§€ì •í•˜ê³ , ë‹¤ìŒ ê²½ë¡œì— **ì €ì¥**í•©ë‹ˆë‹¤:  \n",
    "   **`\\home\\project\\etl_code.py`**\n",
    "\n",
    "---\n",
    "\n",
    "ì´ì œ Python íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìœ¼ë‹ˆ ETL ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e890788",
   "metadata": {},
   "source": [
    "Project Source ìë£Œ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67568d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('source_etl_proejct.zip', <http.client.HTTPMessage at 0x1d74a022100>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "URL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip'\n",
    "file_name = 'source_etl_proejct.zip'\n",
    "urllib.request.urlretrieve(URL, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea4457",
   "metadata": {},
   "source": [
    "## **Importing Libraries and Setting Paths**  \n",
    "\n",
    "ì´ì œ í”„ë¡œì íŠ¸ í´ë”ì— **í•„ìš”í•œ íŒŒì¼ë“¤ì´ ì¤€ë¹„**ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì‹¤ìŠµì—ì„œëŠ” **CSV, JSON, XML í˜•ì‹ì˜ ë°ì´í„°**ë¥¼ **ì¶”ì¶œ(Extract)**í•  ê²ƒì…ë‹ˆë‹¤. ë¨¼ì €, ì ì ˆí•œ Python **ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜¤ê¸°(import)** í•´ì•¼ ê´€ë ¨ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ëª…:**\n",
    "\n",
    "1ï¸âƒ£ **`xml` ë¼ì´ë¸ŒëŸ¬ë¦¬**:  \n",
    "- **`.xml` íŒŒì¼ í˜•ì‹**ì˜ ì •ë³´ë¥¼ íŒŒì‹±(parse)í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "2ï¸âƒ£ **`pandas` ë¼ì´ë¸ŒëŸ¬ë¦¬**:  \n",
    "- **`.csv`** ë° **`.json`** íŒŒì¼ í˜•ì‹ì„ ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "- ë°ì´í„°ë¥¼ **ë°ì´í„°í”„ë ˆì„(DataFrame)** í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "3ï¸âƒ£ **`glob` ë¼ì´ë¸ŒëŸ¬ë¦¬**:  \n",
    "- **íŒŒì¼ ê²½ë¡œ**ì™€ **íŒŒì¼ í˜•ì‹** ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.  \n",
    "- íŠ¹ì • ë””ë ‰í† ë¦¬ì— ìˆëŠ” **ëª¨ë“  íŒŒì¼ì„ ê²€ìƒ‰**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "4ï¸âƒ£ **`datetime` ë¼ì´ë¸ŒëŸ¬ë¦¬**:  \n",
    "- **ë¡œê·¸(logging)** ì‹œì ì— **ë‚ ì§œì™€ ì‹œê°„** ì •ë³´ë¥¼ ê¸°ë¡í•  ë•Œ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ **ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜:**\n",
    "- **`glob`**, **`xml`**, **`datetime`**ì€ **Python ë‚´ì¥ ë¼ì´ë¸ŒëŸ¬ë¦¬**ì´ë¯€ë¡œ ë³„ë„ì˜ ì„¤ì¹˜ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  \n",
    "- ê·¸ëŸ¬ë‚˜ **`pandas`**ëŠ” ë³„ë„ë¡œ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ‘‰ **pandas ì„¤ì¹˜ ëª…ë ¹ì–´**:  \n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **ì „ì²´ ì½”ë“œ ì˜ˆì‹œ:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "path = \"/home/project/\"\n",
    "```\n",
    "\n",
    "ì´ì œ **í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬**ë¥¼ ê°€ì ¸ì˜¤ê³  **ê²½ë¡œ ì„¤ì •**ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15220c",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-warning'>\n",
    "\n",
    "### **ğŸ“Œ ì£¼ì˜:**  \n",
    "XML íŒŒì¼ì„ íŒŒì‹±í•  ë•Œ, **`xml.etree` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ `ElementTree` í•¨ìˆ˜ë§Œ import**í•©ë‹ˆë‹¤.  \n",
    "ì´ í•¨ìˆ˜ëŠ” **XML ë°ì´í„°ë¥¼ íŒŒì‹±**í•˜ëŠ” ë° í•„ìš”í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ **ê¸€ë¡œë²Œ ê²½ë¡œ ì„¤ì •:**  \n",
    "ì½”ë“œ ë‚´ ëª¨ë“  í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë  ë‘ ê°œì˜ **íŒŒì¼ ê²½ë¡œ**ë¥¼ **ê¸€ë¡œë²Œ ë³€ìˆ˜**ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **`transformed_data.csv`**:  \n",
    "   - **ìµœì¢… ì¶œë ¥ ë°ì´í„°**ë¥¼ ì €ì¥í•  íŒŒì¼ë¡œ, **ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬(load)**í•  ì¤€ë¹„ê°€ ëœ ë°ì´í„°ë¥¼ ë‹´ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "2. **`log_file.txt`**:  \n",
    "   - ëª¨ë“  **ë¡œê·¸(log)** ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” íŒŒì¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **ê²½ë¡œ ì„¤ì • ì½”ë“œ ì˜ˆì‹œ:**\n",
    "\n",
    "```python\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# ê¸€ë¡œë²Œ ê²½ë¡œ ì„¤ì •\n",
    "transformed_data_path = \"/home/project/transformed_data.csv\"\n",
    "log_file_path = \"/home/project/log_file.txt\"\n",
    "```\n",
    "\n",
    "ì´ì œ **ë°ì´í„° ì €ì¥ ê²½ë¡œ**ì™€ **ë¡œê·¸ íŒŒì¼ ê²½ë¡œ**ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ˜Š\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c262e4e",
   "metadata": {},
   "source": [
    "##  **Task 1: Extraction - êµ¬í˜„ ìš”ì•½**\n",
    "\n",
    "ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹(CSV, JSON, XML)ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” **ETL(Extract, Transform, Load)** ê³¼ì •ì˜ **ì¶”ì¶œ(Extraction)** ë¶€ë¶„ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œëŠ” ê° íŒŒì¼ í˜•ì‹ì— ëŒ€í•´ **ë³„ë„ì˜ í•¨ìˆ˜**ë¥¼ ì •ì˜í•˜ê³ , ëª¨ë“  íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” **`extract()` í•¨ìˆ˜**ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **1ï¸âƒ£ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ: `extract_from_csv()`**  \n",
    "CSV íŒŒì¼ì„ ì½ê¸° ìœ„í•´ **`pandas.read_csv()`** í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def extract_from_csv(file_to_process): \n",
    "    dataframe = pd.read_csv(file_to_process) \n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **2ï¸âƒ£ JSON íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ: `extract_from_json()`**  \n",
    "JSON íŒŒì¼ì„ ì½ê¸° ìœ„í•´ **`pandas.read_json()`** í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©°, **`lines=True`** ì¸ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ ê° ì¤„ì„ JSON ê°ì²´ë¡œ ì½ìŠµë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "def extract_from_json(file_to_process): \n",
    "    dataframe = pd.read_json(file_to_process, lines=True) \n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **3ï¸âƒ£ XML íŒŒì¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ: `extract_from_xml()`**  \n",
    "XML íŒŒì¼ì„ íŒŒì‹±í•˜ê¸° ìœ„í•´ **`ElementTree`**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” **`name`**, **`height`**, **`weight`** ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  **Pandas DataFrame**ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_from_xml(file_to_process): \n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"]) \n",
    "    tree = ET.parse(file_to_process) \n",
    "    root = tree.getroot() \n",
    "    \n",
    "    for person in root: \n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\": name, \"height\": height, \"weight\": weight}])], ignore_index=True) \n",
    "    \n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **4ï¸âƒ£ ëª¨ë“  íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜: `extract()`**  \n",
    "`glob` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ **ëª¨ë“  CSV, JSON, XML íŒŒì¼ì„ íƒìƒ‰**í•˜ê³ , ê° íŒŒì¼ í˜•ì‹ì— ë§ëŠ” í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "import glob\n",
    "\n",
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name', 'height', 'weight'])  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "     \n",
    "    # CSV íŒŒì¼ ì²˜ë¦¬\n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True) \n",
    "         \n",
    "    # JSON íŒŒì¼ ì²˜ë¦¬\n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True) \n",
    "     \n",
    "    # XML íŒŒì¼ ì²˜ë¦¬\n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True) \n",
    "         \n",
    "    return extracted_data\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **etl_code.pyì— ì¶”ê°€í•  ì½”ë“œ:**  \n",
    "ì´ì œ ìœ„ì—ì„œ ì‘ì„±í•œ ëª¨ë“  í•¨ìˆ˜ë¥¼ **`etl_code.py`** íŒŒì¼ì— ì¶”ê°€í•˜ë©´ **ì¶”ì¶œ(Extraction)** ë¶€ë¶„ì˜ êµ¬í˜„ì´ ì™„ë£Œë©ë‹ˆë‹¤.\n",
    "\n",
    "- **`extract_from_csv()`**  \n",
    "- **`extract_from_json()`**  \n",
    "- **`extract_from_xml()`**  \n",
    "- **`extract()`**\n",
    "\n",
    "ì´ì œ ë°ì´í„°ì…‹ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac5e0b",
   "metadata": {},
   "source": [
    "## **Task 2: Transformation**  \n",
    "\n",
    "ë°ì´í„°ì…‹ì˜ **`height`(í‚¤)** ê°’ì€ **ì¸ì¹˜(inches)** ë‹¨ìœ„ë¡œ, **`weight`(ëª¸ë¬´ê²Œ)** ê°’ì€ **íŒŒìš´ë“œ(pounds)** ë‹¨ìœ„ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  \n",
    "ê·¸ëŸ¬ë‚˜, ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ ìš”êµ¬í•˜ëŠ” í˜•ì‹ì€:  \n",
    "- **í‚¤(height)**: **ë¯¸í„°(meters)**  \n",
    "- **ëª¸ë¬´ê²Œ(weight)**: **í‚¬ë¡œê·¸ë¨(kilograms)**  \n",
    "\n",
    "ë”°ë¼ì„œ, ë‹¨ìœ„ë¥¼ ë³€í™˜í•˜ê³  **ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼**í•˜ëŠ” **`transform()` í•¨ìˆ˜**ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **`transform()` í•¨ìˆ˜ ì„¤ëª…:**  \n",
    "- **í‚¤ ë³€í™˜:**  \n",
    "  - **1 ì¸ì¹˜** = **0.0254 ë¯¸í„°**  \n",
    "- **ëª¸ë¬´ê²Œ ë³€í™˜:**  \n",
    "  - **1 íŒŒìš´ë“œ** = **0.45359237 í‚¬ë¡œê·¸ë¨**  \n",
    "- **ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬**ë¡œ ë°˜ì˜¬ë¦¼(**`round()`** í•¨ìˆ˜ ì‚¬ìš©)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **`transform()` í•¨ìˆ˜ ì½”ë“œ:**\n",
    "\n",
    "```python\n",
    "def transform(data): \n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    data['height'] = round(data.height * 0.0254, 2) \n",
    " \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight'] = round(data.weight * 0.45359237, 2) \n",
    "    \n",
    "    return data\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **ë³€í™˜ í›„ ë°ì´í„°í”„ë ˆì„ ì˜ˆì‹œ:**\n",
    "\n",
    "| **name**  | **height (m)** | **weight (kg)** |\n",
    "|-----------|-----------------|-----------------|\n",
    "| John      | 1.75            | 70.31           |\n",
    "| Alice     | 1.62            | 60.45           |\n",
    "| Bob       | 1.80            | 78.91           |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ **etl_code.py íŒŒì¼ì— ì¶”ê°€:**  \n",
    "- ìœ„ì˜ **`transform()` í•¨ìˆ˜**ë¥¼ **`etl_code.py`** íŒŒì¼ì— ì¶”ê°€í•˜ë©´ **ë°ì´í„° ë³€í™˜(Transformation)** ë‹¨ê³„ê°€ ì™„ë£Œë©ë‹ˆë‹¤. ğŸ˜Š\n",
    "\n",
    "ì´ì œ **ì¶”ì¶œ(Extraction)**ê³¼ **ë³€í™˜(Transformation)** ë‹¨ê³„ê°€ ëª¨ë‘ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ’ª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b62eab",
   "metadata": {},
   "source": [
    "## **Task 3: Loading and Logging**  \n",
    "\n",
    "ì´ì œ ë³€í™˜ëœ ë°ì´í„°ë¥¼ **CSV íŒŒì¼ë¡œ ì €ì¥(Loading)**í•˜ê³ , ê° ë‹¨ê³„ì˜ ì§„í–‰ ìƒí™©ì„ **ë¡œê·¸(Log)ë¡œ ê¸°ë¡**í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **1ï¸âƒ£ ë°ì´í„° ì ì¬ í•¨ìˆ˜: `load_data()`**  \n",
    "ì´ í•¨ìˆ˜ëŠ” **ë³€í™˜ëœ ë°ì´í„°**ë¥¼ **CSV íŒŒì¼**ë¡œ ì €ì¥í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ“„ **`load_data()` í•¨ìˆ˜ ì½”ë“œ:**  \n",
    "```python\n",
    "def load_data(target_file, transformed_data): \n",
    "    transformed_data.to_csv(target_file, index=False)  # index=Falseë¡œ ì¸ë±ìŠ¤ ì €ì¥ ì•ˆ í•¨\n",
    "```\n",
    "\n",
    "ğŸ“Œ **ì„¤ëª…:**  \n",
    "- **`target_file`**: ë°ì´í„°ë¥¼ ì €ì¥í•  **íŒŒì¼ ê²½ë¡œ**  \n",
    "- **`transformed_data`**: **ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„**  \n",
    "- **`to_csv()`**: ë°ì´í„°ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” **Pandas ë©”ì„œë“œ**  \n",
    "- **`index=False`**: ì¸ë±ìŠ¤ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥í•˜ì§€ ì•Šë„ë¡ ì„¤ì •  \n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **2ï¸âƒ£ ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜: `log_progress()`**  \n",
    "ì´ í•¨ìˆ˜ëŠ” ê° ì‘ì—… ë‹¨ê³„ì˜ **ì§„í–‰ ìƒí™©**ì„ **ë¡œê·¸ íŒŒì¼(log_file)**ì— ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ“„ **`log_progress()` í•¨ìˆ˜ ì½”ë“œ:**  \n",
    "```python\n",
    "from datetime import datetime\n",
    "\n",
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%b-%d-%H:%M:%S'  # ì—°-ì›”-ì¼-ì‹œ:ë¶„:ì´ˆ í˜•ì‹\n",
    "    now = datetime.now()  # í˜„ì¬ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°\n",
    "    timestamp = now.strftime(timestamp_format)  # ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    \n",
    "    with open(log_file_path, \"a\") as f:  # ë¡œê·¸ íŒŒì¼ì„ ì¶”ê°€ ëª¨ë“œë¡œ ì—´ê¸°\n",
    "        f.write(timestamp + ',' + message + '\\n')  # ë¡œê·¸ ë©”ì‹œì§€ ê¸°ë¡\n",
    "```\n",
    "\n",
    "ğŸ“Œ **ì„¤ëª…:**  \n",
    "- **`message`**: ë¡œê·¸ì— ê¸°ë¡í•  **ë©”ì‹œì§€**  \n",
    "- **`timestamp_format`**: ë‚ ì§œ ë° ì‹œê°„ í˜•ì‹ ì •ì˜  \n",
    "- **`strftime()`**: **ë‚ ì§œ/ì‹œê°„ì„ ë¬¸ìì—´**ë¡œ ë³€í™˜  \n",
    "- **`with open(log_file_path, \"a\")`**: ë¡œê·¸ íŒŒì¼ì„ **ì¶”ê°€ ëª¨ë“œ**ë¡œ ì—´ê³ , ë¡œê·¸ ë©”ì‹œì§€ë¥¼ ê¸°ë¡  \n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **3ï¸âƒ£ ëª¨ë“  í•¨ìˆ˜ í†µí•©í•˜ê¸°:**  \n",
    "- **`load_data()`**ì™€ **`log_progress()`** í•¨ìˆ˜ë¥¼ **`etl_code.py`** íŒŒì¼ì— ì¶”ê°€í•©ë‹ˆë‹¤.  \n",
    "- ì´ë¡œì¨ **ETL(Extract, Transform, Load)**ì˜ ëª¨ë“  ê¸°ëŠ¥ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **etl_code.py ìµœì¢… ì½”ë“œ êµ¬ì¡°:**  \n",
    "```python\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "transformed_data_path = \"/home/project/transformed_data.csv\"\n",
    "log_file_path = \"/home/project/log_file.txt\"\n",
    "\n",
    "# Extract functions (CSV, JSON, XML)\n",
    "def extract_from_csv(file_to_process):\n",
    "    return pd.read_csv(file_to_process)\n",
    "\n",
    "def extract_from_json(file_to_process):\n",
    "    return pd.read_json(file_to_process, lines=True)\n",
    "\n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text)\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\": name, \"height\": height, \"weight\": weight}])], ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "# Transformation function\n",
    "def transform(data):\n",
    "    data['height'] = round(data.height * 0.0254, 2)\n",
    "    data['weight'] = round(data.weight * 0.45359237, 2)\n",
    "    return data\n",
    "\n",
    "# Loading function\n",
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file, index=False)\n",
    "\n",
    "# Logging function\n",
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%b-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file_path, \"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **ETL í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ!**  \n",
    "ì´ì œ ëª¨ë“  **ETL í•¨ìˆ˜(Extract, Transform, Load)**ê°€ êµ¬í˜„ë˜ì—ˆìœ¼ë©°,  \n",
    "**`etl_code.py`** íŒŒì¼ì— ì¶”ê°€í•œ í›„ **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**ì„ í†µí•´ ETL í”„ë¡œì„¸ìŠ¤ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a655757",
   "metadata": {},
   "source": [
    "### **Execution of Code (ì½”ë“œ ì‹¤í–‰)**  \n",
    "\n",
    "`etl_code.py` íŒŒì¼ì„ **í„°ë¯¸ë„ ì‰˜**ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤:  \n",
    "\n",
    "```bash\n",
    "python3.11 etl_code.py\n",
    "```  \n",
    "\n",
    "### âœ… **ì½”ë“œ ì‹¤í–‰ ê²°ê³¼:**  \n",
    "- ì‹¤í–‰ì´ ì™„ë£Œë˜ë©´, **í„°ë¯¸ë„ì—ì„œ ì¶œë ¥ ë©”ì‹œì§€**ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "- ê° ì‘ì—… ë‹¨ê³„ì—ì„œ **`print` ëª…ë ¹ì–´**ë¡œ ì¶œë ¥ëœ ê²°ê³¼ê°€ í„°ë¯¸ë„ì— í‘œì‹œë©ë‹ˆë‹¤.\n",
    "\n",
    "<img src='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/images/code_output.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c2cb4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **ë¡œê·¸ íŒŒì¼(log_file.txt) ë‚´ìš© í™•ì¸:**  \n",
    "ì½”ë“œ ì‹¤í–‰ í›„, **`log_file.txt`** íŒŒì¼ì„ ì—´ë©´ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡ëœ **ì§„í–‰ ìƒí™©**ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "<img src='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/images/log_file.png' />\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **ì‹¤í–‰ íë¦„ ìš”ì•½:**\n",
    "1. **í„°ë¯¸ë„ì—ì„œ `etl_code.py` ì‹¤í–‰**  \n",
    "2. **í„°ë¯¸ë„ ì¶œë ¥ í™•ì¸ (print ëª…ë ¹ì–´ ê²°ê³¼)**  \n",
    "3. **`log_file.txt` í™•ì¸ (ê° ë‹¨ê³„ì˜ ì‘ì—… ê¸°ë¡)**\n",
    "\n",
    "ì´ì œ ETL í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa647ea4",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127b860",
   "metadata": {},
   "source": [
    "# Practice Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d9bced0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('datasource.zip', <http.client.HTTPMessage at 0x1d75b6d0280>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "URL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip '\n",
    "file_name = 'datasource.zip'\n",
    "urllib.request.urlretrieve(URL, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7acfbb1",
   "metadata": {},
   "source": [
    "### âœ… **Practice Exercise Guide:**\n",
    "\n",
    "ì•„ë˜ëŠ” **ETL ì‹¤ìŠµ ê³¼ì œ**ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ **ë‹¨ê³„ë³„ ê°€ì´ë“œ**ì…ë‹ˆë‹¤. ê° ë‹¨ê³„ë¥¼ ë”°ë¼ê°€ë©° **CSV, JSON, XML** í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œ, ë³€í™˜, ì ì¬, ë¡œê·¸ ê¸°ë¡í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‚ **1ï¸âƒ£ ë””ë ‰í† ë¦¬ ë° íŒŒì¼ ìƒì„±:**\n",
    "\n",
    "1. **ë°ì´í„° ì†ŒìŠ¤ í´ë” ìƒì„±:**  \n",
    "   ```bash\n",
    "   mkdir -p /home/project/data_source\n",
    "   ```\n",
    "\n",
    "2. **ë””ë ‰í† ë¦¬ ë³€ê²½:**  \n",
    "   ```bash\n",
    "   cd /home/project/data_source\n",
    "   ```\n",
    "\n",
    "3. **ìƒˆ Python íŒŒì¼ ìƒì„±:**  \n",
    "   ```bash\n",
    "   touch etl_practice.py\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“¦ **2ï¸âƒ£ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ:**\n",
    "\n",
    "- ë‹¤ìš´ë¡œë“œí•œ ë°ì´í„°ë¥¼ **data_source** í´ë”ì— ì €ì¥í•˜ê³  **ì••ì¶•ì„ í•´ì œ**í•©ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§‘â€ğŸ’» **3ï¸âƒ£ etl_practice.py íŒŒì¼ ì‘ì„±:**\n",
    "\n",
    "**etl_practice.py**ì— ì•„ë˜ ê¸°ëŠ¥ë“¤ì„ ë‹¨ê³„ë³„ë¡œ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **Step 1: Extraction (ë°ì´í„° ì¶”ì¶œ)**\n",
    "\n",
    "ê° íŒŒì¼ í˜•ì‹ì— ëŒ€í•´ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤:\n",
    "\n",
    "- **CSV:** `extract_from_csv()`\n",
    "- **JSON:** `extract_from_json()`\n",
    "- **XML:** `extract_from_xml()`\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "\n",
    "def extract_from_csv(file_to_process):\n",
    "    return pd.read_csv(file_to_process)\n",
    "\n",
    "def extract_from_json(file_to_process):\n",
    "    return pd.read_json(file_to_process, lines=True)\n",
    "\n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for car in root:\n",
    "        car_model = car.find(\"car_model\").text\n",
    "        year_of_manufacture = int(car.find(\"year_of_manufacture\").text)\n",
    "        price = float(car.find(\"price\").text)\n",
    "        fuel = car.find(\"fuel\").text\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"car_model\": car_model, \"year_of_manufacture\": year_of_manufacture, \"price\": price, \"fuel\": fuel}])], ignore_index=True)\n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **Step 2: Transformation (ë°ì´í„° ë³€í™˜)**\n",
    "\n",
    "`price` ê°’ì„ **ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬**ë¡œ ë°˜ì˜¬ë¦¼í•˜ëŠ” ë³€í™˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "def transform(data):\n",
    "    data['price'] = round(data['price'], 2)\n",
    "    return data\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **Step 3: Loading (ë°ì´í„° ì ì¬)**\n",
    "\n",
    "ë³€í™˜ëœ ë°ì´í„°ë¥¼ **transformed_data.csv** íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file, index=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ **Step 4: Logging (ë¡œê·¸ ê¸°ë¡)**\n",
    "\n",
    "ê° ë‹¨ê³„ì˜ ì§„í–‰ ìƒí™©ì„ **log_file.txt**ì— ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "\n",
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%b-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"log_file.txt\", \"a\") as f:\n",
    "        f.write(timestamp + \",\" + message + \"\\n\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ª **Step 5: Testing (í…ŒìŠ¤íŠ¸)**\n",
    "\n",
    "ì „ì²´ ETL í”„ë¡œì„¸ìŠ¤ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\", \"price\", \"fuel\"])\n",
    "\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_csv(csvfile)], ignore_index=True)\n",
    "\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_json(jsonfile)], ignore_index=True)\n",
    "\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_xml(xmlfile)], ignore_index=True)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log_progress(\"ETL process started\")\n",
    "\n",
    "    # Extraction\n",
    "    data = extract()\n",
    "    log_progress(\"Extraction completed\")\n",
    "\n",
    "    # Transformation\n",
    "    transformed_data = transform(data)\n",
    "    log_progress(\"Transformation completed\")\n",
    "\n",
    "    # Loading\n",
    "    load_data(\"transformed_data.csv\", transformed_data)\n",
    "    log_progress(\"Loading completed\")\n",
    "\n",
    "    log_progress(\"ETL process finished\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **ì‹¤í–‰ ë°©ë²•:**\n",
    "\n",
    "1. **í„°ë¯¸ë„ì—ì„œ etl_practice.py ì‹¤í–‰:**  \n",
    "   ```bash\n",
    "   python3 etl_practice.py\n",
    "   ```\n",
    "\n",
    "2. **ë¡œê·¸ íŒŒì¼ í™•ì¸:**  \n",
    "   ```bash\n",
    "   cat log_file.txt\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‰ **ì™„ë£Œ!**\n",
    "\n",
    "ì´ì œ ëª¨ë“  ETL ë‹¨ê³„ë¥¼ êµ¬í˜„í•˜ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!  \n",
    "ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ **Discussion Forum**ì— ì§ˆë¬¸ì„ ì˜¬ë ¤ë³´ì„¸ìš”. ğŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
